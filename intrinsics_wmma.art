/*
 * D = A * B + C
 *
 * Where:
 *
 * A:    (  -> K )
 *       (       )
 *       (| M    )
 *       (V      )
 *
 * B:    (  -> N )
 *       (       )
 *       (| K    )
 *       (V      )
 *
 * C, D: (  -> N )
 *       (       )
 *       (| M    )
 *       (V      )
 */


//See llvm-project/llvm/test/CodeGen/NVPTX $ python wmma-ptx71-sm80.py for a somewhat decent list of operations.
//Matrix load operations for each of the three inputs. Separate operations need to be used as the data layout on device changes with the operator in question.
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.a.row.f16.p1")]
fn nvvm_load_a (_addr : &addrspace(1)i8) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.b.row.f16.p1")]
fn nvvm_load_b (_addr : &addrspace(1)i8) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.c.row.f16.p1")]
fn nvvm_load_c (_addr : &addrspace(1)i8) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);

//Strided variants. The default stride with these operations is 16, larger strides can be specified with these operations.
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.a.row.stride.f16.p1")]
fn nvvm_load_a_stride (_addr : &addrspace(1)i8, _stride : i32) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.b.row.stride.f16.p1")]
fn nvvm_load_b_stride (_addr : &addrspace(1)i8, _stride : i32) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.load.c.row.stride.f16.p1")]
fn nvvm_load_c_stride (_addr : &addrspace(1)i8, _stride : i32) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);

//The actual WMMA operation. No strides or anything; this operates on registers.
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.mma.row.row.f16.f16")]
fn nvvm_wmma (_a0 : simd[f16 * 2], _a1 : simd[f16 * 2], _a2 : simd[f16 * 2], _a3 : simd[f16 * 2], _a4 : simd[f16 * 2], _a5 : simd[f16 * 2], _a6 : simd[f16 * 2], _a7 : simd[f16 * 2], _b0 : simd[f16 * 2], _b1 : simd[f16 * 2], _b2 : simd[f16 * 2], _b3 : simd[f16 * 2], _b4 : simd[f16 * 2], _b5 : simd[f16 * 2], _b6 : simd[f16 * 2], _b7 : simd[f16 * 2], _c0 : simd[f16 * 2], _c1 : simd[f16 * 2], _c2 : simd[f16 * 2], _c3 : simd[f16 * 2]) -> (simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]);

//Store the result matrix back on disk.
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.store.d.row.f16.p1")]
fn nvvm_store_d (_addr : &mut addrspace(1)i8, simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2]) -> ();

//Again, a strided variant of that operation.
#[import(cc = "device", name = "llvm.nvvm.wmma.m16n16k16.store.d.row.stride.f16.p1")]
fn nvvm_store_d_stride (_addr : &mut addrspace(1)i8, simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], simd[f16 * 2], _stride : i32) -> ();
