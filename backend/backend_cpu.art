/*
 * D = A * B + C
 *
 * Where:
 *
 * A:    (  -> K )
 *       (       )
 *       (| M    )
 *       (V      )
 *
 * B:    (  -> N )
 *       (       )
 *       (| K    )
 *       (V      )
 *
 * C, D: (  -> N )
 *       (       )
 *       (| M    )
 *       (V      )
 */

fn print_matrix (t : Tensor[f16]) -> () {
    for y in range(0, t.y_dim) {
        for x in range(0, t.x_dim) {
            print_f32(t.data(addr_tensor(x, y, t)) as f32);
            if (x < t.x_dim - 1) { print_string(", "); }
        }
        print_string("\n");
    }
}


fn matrix_multiply_naive (a : Tensor[f16], b : Tensor[f16], c : Tensor[f16], r : Tensor[f16]) -> () {
    let m = a.y_dim;
    let n = b.x_dim;
    //assert(a.x_dim == b.y_dim);
    let k = a.x_dim;

    let print_progress = (m as i64 * n as i64 * k as i64) > (128 * 128 * 128);

    for y in range(0, m) {
        for x in range(0, n) {
            let mut rv = 0 : f32;

            for i in range(0, k) {
                let av = a.data(addr_tensor(i, y, a)) as f32;
                let bv = b.data(addr_tensor(x, i, b)) as f32;

                rv += av * bv;
            }

            let cv = c.data(addr_tensor(x, y, c)) as f32;

            r.data(addr_tensor(x, y, r)) = (cv + rv) as f16;
        }
        if (print_progress) {
            print_string("\r");
            print_i32(y * 100 / m);
            print_string("%");
            print_flush();
        }
    }
    if (print_progress) {
        print_string("\r");
    }
}
